"""
File Storage Service Protocol

Defines the interface that Infrastructure Layer must implement
for file storage operations. Used by Application Layer use cases.

Architecture Notes:
    - Part of Application Layer (Ports/Interfaces)
    - Implements Dependency Inversion Principle (SOLID)
    - Infrastructure Layer provides concrete implementation
    - Enables easy testing with mock implementations
"""

from pathlib import Path
from typing import Any, Protocol
from uuid import UUID


class FileStorageServiceProtocol(Protocol):
    """
    Protocol (interface) for file storage service.

    Defines the contract that Infrastructure Layer's FileStorageService
    must implement. This follows Dependency Inversion Principle from SOLID.

    Two storage models are used:
        1. Upload storage: /tmp/fastbidder/uploads/{file_id}/{filename}
           - For files uploaded before job creation
           - User gets file_id to reference in matching request

        2. Job storage: /tmp/fastbidder/{job_id}/input|output/
           - For files during job processing
           - Created when job starts by copying from uploads

    Methods are grouped by storage model:
        - Upload methods: save_uploaded_file, extract_file_metadata, extract_file_preview
        - Job methods: file_exists, get_file_metadata, upload_file, get_file_path
        - Result methods: get_result_file_path, result_file_exists
        - Cleanup methods: cleanup_job, cleanup_old_jobs

    Note:
        Actual implementation in Infrastructure Layer:
        src/infrastructure/file_storage/file_storage_service.py
    """

    # ========================================
    # Upload Storage Methods (uploads/{file_id}/)
    # ========================================

    async def save_uploaded_file(
        self, file_id: UUID, file_data: bytes, filename: str
    ) -> Path:
        """
        Save uploaded file to temporary upload storage.

        Storage path: /tmp/fastbidder/uploads/{file_id}/{filename}

        Args:
            file_id: Unique identifier for uploaded file (generated by use case)
            file_data: Raw file bytes from multipart upload
            filename: Original filename from user (preserved in storage)

        Returns:
            Path to saved file (absolute path)

        Raises:
            ValueError: If extension is invalid (.xlsx/.xls only)
            FileSizeExceededError: If file too large (>10MB)
            OSError: If file cannot be written
        """
        ...

    async def extract_file_metadata(self, file_path: Path) -> dict[str, Any]:
        """
        Extract metadata from Excel file.

        Args:
            file_path: Path to Excel file

        Returns:
            Dict with metadata:
            {
                'filename': str,
                'size': int (bytes),
                'size_mb': float,
                'sheets_count': int,
                'rows_count': int,
                'columns_count': int,
                'created_at': str (ISO format)
            }

        Raises:
            FileNotFoundError: If file not found
            ExcelParsingError: If file cannot be parsed
        """
        ...

    async def extract_file_preview(
        self, file_path: Path, rows: int = 5
    ) -> list[dict[str, Any]]:
        """
        Extract preview of first N rows from Excel file.

        Args:
            file_path: Path to Excel file
            rows: Number of rows to extract (default 5)

        Returns:
            List of dicts (each dict = one row with column names as keys)

        Raises:
            FileNotFoundError: If file not found
            ExcelParsingError: If file cannot be parsed
        """
        ...

    # ========================================
    # Job Storage Methods ({job_id}/input|output/)
    # ========================================

    async def file_exists(self, job_id: UUID, file_type: str) -> bool:
        """
        Check if specific file exists in job storage.

        Args:
            job_id: UUID of the job
            file_type: Type of file ("working", "reference", "result")

        Returns:
            True if file exists, False otherwise
        """
        ...

    async def get_file_metadata(self, job_id: UUID, file_type: str) -> dict[str, Any]:
        """
        Get file metadata (size, format, timestamps) from job storage.

        Args:
            job_id: UUID of the job
            file_type: Type of file ("working", "reference", "result")

        Returns:
            Dict with metadata (size, size_mb, format, exists, created_at, modified_at)

        Raises:
            FileNotFoundError: If file does not exist
        """
        ...

    async def upload_file(
        self,
        job_id: UUID,
        file_data: bytes,
        filename: str,
        file_type: str,
    ) -> Path:
        """
        Upload file to job's input directory.

        Storage path: /tmp/fastbidder/{job_id}/input/{file_type}_file.xlsx

        Args:
            job_id: Unique job identifier
            file_data: Raw file bytes
            filename: Original filename (for extension validation only)
            file_type: Type of file ("working" or "reference")

        Returns:
            Path to saved file

        Raises:
            ValueError: If extension invalid
            FileSizeExceededError: If file too large
            OSError: If cannot write
        """
        ...

    def get_file_path(self, job_id: UUID, file_type: str) -> Path:
        """
        Get path to file in job storage (may or may not exist).

        Args:
            job_id: Unique job identifier
            file_type: Type of file ("working", "reference", "result")

        Returns:
            Path object pointing to file location
        """
        ...

    # ========================================
    # Result File Methods
    # ========================================

    def get_result_file_path(self, job_id: UUID) -> Path:
        """
        Get path to result file for completed job.

        Storage path: /tmp/fastbidder/{job_id}/output/result.xlsx

        Args:
            job_id: UUID of the job

        Returns:
            Path to result file (may or may not exist)
        """
        ...

    def result_file_exists(self, job_id: UUID) -> bool:
        """
        Check if result file exists for job.

        Args:
            job_id: UUID of the job

        Returns:
            True if result file exists, False otherwise
        """
        ...

    # ========================================
    # Cleanup Methods
    # ========================================

    async def cleanup_job(self, job_id: UUID) -> None:
        """
        Delete all files and directories for a job (hard delete).

        Args:
            job_id: Unique job identifier

        Raises:
            OSError: If directory cannot be deleted
        """
        ...

    async def cleanup_old_jobs(self, hours: int = 24) -> int:
        """
        Cleanup jobs older than specified hours.

        Args:
            hours: Age threshold in hours (default 24)

        Returns:
            Number of job directories successfully cleaned up
        """
        ...
